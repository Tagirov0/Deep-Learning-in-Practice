{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "TsuA0MtYs9nc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLbLs7EFejXc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/JaidedAI/EasyOCR.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkGYnVHKjC9Q",
        "outputId": "250a9b5d-9089-42b2-f8ce-ebae62fbd426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/EasyOCR/trainer/all_data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/EasyOCR/trainer/all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpH3_Sfo1RUc"
      },
      "outputs": [],
      "source": [
        "!unzip /content/EasyOCR/trainer/all_data/en_val.zip\n",
        "!unzip /content/EasyOCR/trainer/all_data/en_train_filtered.zip\n",
        "\n",
        "!rm /content/EasyOCR/trainer/all_data/folder.txt\n",
        "!rm /content/EasyOCR/trainer/all_data/en_val.zip\n",
        "!rm /content/EasyOCR/trainer/all_data/en_train_filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0aascdNjFwg",
        "outputId": "fa10aae6-5219-4119-ea0b-9311685d9585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/EasyOCR/trainer\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sooI7ZIEJYu_",
        "outputId": "7f471e70-3373-4699-8903-f428d0753e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PIywV9_WZqNNfUIk6-bs598fX7OZTcbY\n",
            "To: /content/EasyOCR/trainer/cyrillic_g2.pth\n",
            "100% 15.3M/15.3M [00:00<00:00, 27.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown \"1PIywV9_WZqNNfUIk6-bs598fX7OZTcbY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORToxtllgGm_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "import yaml\n",
        "from utils import AttrDict\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb65PNq5gJZJ"
      },
      "outputs": [],
      "source": [
        "cudnn.benchmark = True\n",
        "cudnn.deterministic = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mjGZ8gMTPc1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "from model import Model\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from utils import CTCLabelConverter, AttnLabelConverter, Averager\n",
        "from dataset import hierarchical_dataset, AlignCollate, Batch_Balanced_Dataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def count_parameters(model):\n",
        "    print(\"Modules, Parameters\")\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        #table.add_row([name, param])\n",
        "        total_params+=param\n",
        "        print(name, param)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "def train(opt, show_number = 2, amp=False):\n",
        "    \"\"\" dataset preparation \"\"\"\n",
        "    if not opt.data_filtering_off:\n",
        "        print('Filtering the images containing characters which are not in opt.character')\n",
        "        print('Filtering the images whose label is longer than opt.batch_max_length')\n",
        "\n",
        "    opt.select_data = opt.select_data.split('-')\n",
        "    opt.batch_ratio = opt.batch_ratio.split('-')\n",
        "    train_dataset = Batch_Balanced_Dataset(opt)\n",
        "\n",
        "    log = open(f'./saved_models/{opt.experiment_name}/log_dataset.txt', 'a', encoding=\"utf8\")\n",
        "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD, contrast_adjust=opt.contrast_adjust)\n",
        "    valid_dataset, valid_dataset_log = hierarchical_dataset(root=opt.valid_data, opt=opt)\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=min(32, opt.batch_size),\n",
        "        shuffle=True,  # 'True' to check training progress with validation function.\n",
        "        num_workers=int(opt.workers), prefetch_factor=512,\n",
        "        collate_fn=AlignCollate_valid, pin_memory=True)\n",
        "    log.write(valid_dataset_log)\n",
        "    print('-' * 80)\n",
        "    log.write('-' * 80 + '\\n')\n",
        "    log.close()\n",
        "    \n",
        "    \"\"\" model configuration \"\"\"\n",
        "    if 'CTC' in opt.Prediction:\n",
        "        converter = CTCLabelConverter(opt.character)\n",
        "    else:\n",
        "        converter = AttnLabelConverter(opt.character)\n",
        "    opt.num_class = len(converter.character)\n",
        "\n",
        "    if opt.rgb:\n",
        "        opt.input_channel = 3\n",
        "    model = Model(opt)\n",
        "    print('model input parameters', opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel,\n",
        "          opt.hidden_size, opt.num_class, opt.batch_max_length, opt.Transformation, opt.FeatureExtraction,\n",
        "          opt.SequenceModeling, opt.Prediction)\n",
        "\n",
        "    if opt.saved_model != '':\n",
        "        pretrained_dict = torch.load(opt.saved_model)\n",
        "        if opt.new_prediction:\n",
        "            model.Prediction = nn.Linear(model.SequenceModeling_output, len(pretrained_dict['module.Prediction.weight']))  \n",
        "        \n",
        "        model = torch.nn.DataParallel(model).to(device) \n",
        "        print(f'loading pretrained model from {opt.saved_model}')\n",
        "        if opt.FT:\n",
        "            model.load_state_dict(pretrained_dict, strict=False)\n",
        "        else:\n",
        "            model.load_state_dict(pretrained_dict)\n",
        "        if opt.new_prediction:\n",
        "            model.module.Prediction = nn.Linear(model.module.SequenceModeling_output, opt.num_class)  \n",
        "            for name, param in model.module.Prediction.named_parameters():\n",
        "                if 'bias' in name:\n",
        "                    init.constant_(param, 0.0)\n",
        "                elif 'weight' in name:\n",
        "                    init.kaiming_normal_(param)\n",
        "            model = model.to(device) \n",
        "    else:\n",
        "        # weight initialization\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'localization_fc2' in name:\n",
        "                print(f'Skip {name} as it is already initialized')\n",
        "                continue\n",
        "            try:\n",
        "                if 'bias' in name:\n",
        "                    init.constant_(param, 0.0)\n",
        "                elif 'weight' in name:\n",
        "                    init.kaiming_normal_(param)\n",
        "            except Exception as e:  # for batchnorm.\n",
        "                if 'weight' in name:\n",
        "                    param.data.fill_(1)\n",
        "                continue\n",
        "        model = torch.nn.DataParallel(model).to(device)\n",
        "    \n",
        "    model.train() \n",
        "    print(\"Model:\")\n",
        "    print(model)\n",
        "    count_parameters(model)\n",
        "    \n",
        "    \"\"\" setup loss \"\"\"\n",
        "    if 'CTC' in opt.Prediction:\n",
        "        criterion = torch.nn.CTCLoss(zero_infinity=True).to(device)\n",
        "    else:\n",
        "        criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)  # ignore [GO] token = ignore index 0\n",
        "    # loss averager\n",
        "    loss_avg = Averager()\n",
        "\n",
        "    # freeze some layers\n",
        "    try:\n",
        "        if opt.freeze_FeatureFxtraction:\n",
        "            for param in model.module.FeatureExtraction.parameters():\n",
        "                param.requires_grad = False\n",
        "        if opt.freeze_SequenceModeling:\n",
        "            for param in model.module.SequenceModeling.parameters():\n",
        "                param.requires_grad = False\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # filter that only require gradient decent\n",
        "    filtered_parameters = []\n",
        "    params_num = []\n",
        "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
        "        filtered_parameters.append(p)\n",
        "        params_num.append(np.prod(p.size()))\n",
        "    print('Trainable params num : ', sum(params_num))\n",
        "    # [print(name, p.numel()) for name, p in filter(lambda p: p[1].requires_grad, model.named_parameters())]\n",
        "\n",
        "    # setup optimizer\n",
        "    if opt.optim=='adam':\n",
        "        #optimizer = optim.Adam(filtered_parameters, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "        optimizer = optim.Adam(filtered_parameters)\n",
        "    else:\n",
        "        optimizer = optim.Adadelta(filtered_parameters, lr=opt.lr, rho=opt.rho, eps=opt.eps)\n",
        "    print(\"Optimizer:\")\n",
        "    print(optimizer)\n",
        "\n",
        "    \"\"\" final options \"\"\"\n",
        "    # print(opt)\n",
        "    with open(f'./saved_models/{opt.experiment_name}/opt.txt', 'a', encoding=\"utf8\") as opt_file:\n",
        "        opt_log = '------------ Options -------------\\n'\n",
        "        args = vars(opt)\n",
        "        for k, v in args.items():\n",
        "            opt_log += f'{str(k)}: {str(v)}\\n'\n",
        "        opt_log += '---------------------------------------\\n'\n",
        "        print(opt_log)\n",
        "        opt_file.write(opt_log)\n",
        "\n",
        "    \"\"\" start training \"\"\"\n",
        "    start_iter = 0\n",
        "    if opt.saved_model != '':\n",
        "        try:\n",
        "            start_iter = int(opt.saved_model.split('_')[-1].split('.')[0])\n",
        "            print(f'continue to train, start_iter: {start_iter}')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    start_time = time.time()\n",
        "    best_accuracy = -1\n",
        "    best_norm_ED = -1\n",
        "    i = start_iter\n",
        "\n",
        "    scaler = GradScaler()\n",
        "    t1= time.time()\n",
        "        \n",
        "    while(True):\n",
        "        # train part\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        \n",
        "        if amp:\n",
        "            with autocast():\n",
        "                image_tensors, labels = train_dataset.get_batch()\n",
        "                image = image_tensors.to(device)\n",
        "                text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
        "                batch_size = image.size(0)\n",
        "\n",
        "                if 'CTC' in opt.Prediction:\n",
        "                    preds = model(image, text).log_softmax(2)\n",
        "                    preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
        "                    preds = preds.permute(1, 0, 2)\n",
        "                    torch.backends.cudnn.enabled = False\n",
        "                    cost = criterion(preds, text.to(device), preds_size.to(device), length.to(device))\n",
        "                    torch.backends.cudnn.enabled = True\n",
        "                else:\n",
        "                    preds = model(image, text[:, :-1])  # align with Attention.forward\n",
        "                    target = text[:, 1:]  # without [GO] Symbol\n",
        "                    cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
        "            scaler.scale(cost).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            image_tensors, labels = train_dataset.get_batch()\n",
        "            image = image_tensors.to(device)\n",
        "            text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
        "            batch_size = image.size(0)\n",
        "            if 'CTC' in opt.Prediction:\n",
        "                preds = model(image, text).log_softmax(2)\n",
        "                preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
        "                preds = preds.permute(1, 0, 2)\n",
        "                torch.backends.cudnn.enabled = False\n",
        "                cost = criterion(preds, text.to(device), preds_size.to(device), length.to(device))\n",
        "                torch.backends.cudnn.enabled = True\n",
        "            else:\n",
        "                preds = model(image, text[:, :-1])  # align with Attention.forward\n",
        "                target = text[:, 1:]  # without [GO] Symbol\n",
        "                cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
        "            cost.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip) \n",
        "            optimizer.step()\n",
        "        loss_avg.add(cost)\n",
        "\n",
        "        # validation part\n",
        "        if (i % opt.valInterval == 0) and (i!=0):\n",
        "            print('training time: ', time.time()-t1)\n",
        "            t1=time.time()\n",
        "            elapsed_time = time.time() - start_time\n",
        "            # for log\n",
        "            with open(f'./saved_models/{opt.experiment_name}/log_train.txt', 'a', encoding=\"utf8\") as log:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels,\\\n",
        "                    infer_time, length_of_data = validation(model, criterion, valid_loader, converter, opt, device)\n",
        "                model.train()\n",
        "\n",
        "                # training loss and validation loss\n",
        "                loss_log = f'[{i}/{opt.num_iter}] Train loss: {loss_avg.val():0.5f}, Valid loss: {valid_loss:0.5f}, Elapsed_time: {elapsed_time:0.5f}'\n",
        "                loss_avg.reset()\n",
        "\n",
        "                current_model_log = f'{\"Current_accuracy\":17s}: {current_accuracy:0.3f}, {\"Current_norm_ED\":17s}: {current_norm_ED:0.4f}'\n",
        "\n",
        "                # keep best accuracy model (on valid dataset)\n",
        "                if current_accuracy > best_accuracy:\n",
        "                    best_accuracy = current_accuracy\n",
        "                    torch.save(model.state_dict(), f'./saved_models/{opt.experiment_name}/best_accuracy.pth')\n",
        "                if current_norm_ED > best_norm_ED:\n",
        "                    best_norm_ED = current_norm_ED\n",
        "                    torch.save(model.state_dict(), f'./saved_models/{opt.experiment_name}/best_norm_ED.pth')\n",
        "                best_model_log = f'{\"Best_accuracy\":17s}: {best_accuracy:0.3f}, {\"Best_norm_ED\":17s}: {best_norm_ED:0.4f}'\n",
        "\n",
        "                loss_model_log = f'{loss_log}\\n{current_model_log}\\n{best_model_log}'\n",
        "                print(loss_model_log)\n",
        "                log.write(loss_model_log + '\\n')\n",
        "\n",
        "                # show some predicted results\n",
        "                dashed_line = '-' * 80\n",
        "                head = f'{\"Ground Truth\":25s} | {\"Prediction\":25s} | Confidence Score & T/F'\n",
        "                predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
        "                \n",
        "                #show_number = min(show_number, len(labels))\n",
        "                \n",
        "                start = random.randint(0,len(labels) - show_number )    \n",
        "                for gt, pred, confidence in zip(labels[start:start+show_number], preds[start:start+show_number], confidence_score[start:start+show_number]):\n",
        "                    if 'Attn' in opt.Prediction:\n",
        "                        gt = gt[:gt.find('[s]')]\n",
        "                        pred = pred[:pred.find('[s]')]\n",
        "\n",
        "                    predicted_result_log += f'{gt:25s} | {pred:25s} | {confidence:0.4f}\\t{str(pred == gt)}\\n'\n",
        "                predicted_result_log += f'{dashed_line}'\n",
        "                print(predicted_result_log)\n",
        "                log.write(predicted_result_log + '\\n')\n",
        "                print('validation time: ', time.time()-t1)\n",
        "                t1=time.time()\n",
        "        # save model per 1e+4 iter.\n",
        "        if (i + 1) % 1e+4 == 0:\n",
        "            torch.save(\n",
        "                model.state_dict(), f'./saved_models/{opt.experiment_name}/iter_{i+1}.pth')\n",
        "\n",
        "        if i == opt.num_iter:\n",
        "            print('end the training')\n",
        "            torch.save(model.state_dict(), f'./saved_models/{opt.experiment_name}/iter_{i+1}.pth')\n",
        "            break\n",
        "        i += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kKVpyAQTgYy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import string\n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from nltk.metrics.distance import edit_distance\n",
        "\n",
        "from model import Model\n",
        "from utils import CTCLabelConverter, AttnLabelConverter, Averager\n",
        "from dataset import hierarchical_dataset, AlignCollate\n",
        "\n",
        "def validation(model, criterion, evaluation_loader, converter, opt, device):\n",
        "    \"\"\" validation or evaluation \"\"\"\n",
        "    n_correct = 0\n",
        "    norm_ED = 0\n",
        "    length_of_data = 0\n",
        "    infer_time = 0\n",
        "    valid_loss_avg = Averager()\n",
        "\n",
        "    for i, (image_tensors, labels) in enumerate(evaluation_loader):\n",
        "        batch_size = image_tensors.size(0)\n",
        "        length_of_data = length_of_data + batch_size\n",
        "        image = image_tensors.to(device)\n",
        "        # For max length prediction\n",
        "        length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)\n",
        "        text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)\n",
        "\n",
        "        text_for_loss, length_for_loss = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
        "        \n",
        "        start_time = time.time()\n",
        "        if 'CTC' in opt.Prediction:\n",
        "            preds = model(image, text_for_pred)\n",
        "            forward_time = time.time() - start_time\n",
        "\n",
        "            # Calculate evaluation loss for CTC decoder.\n",
        "            preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
        "            # permute 'preds' to use CTCloss format\n",
        "            cost = criterion(preds.log_softmax(2).permute(1, 0, 2), text_for_loss, preds_size, length_for_loss)\n",
        "\n",
        "            if opt.decode == 'greedy':\n",
        "                # Select max probabilty (greedy decoding) then decode index to character\n",
        "                _, preds_index = preds.max(2)\n",
        "                preds_index = preds_index.view(-1)\n",
        "                preds_str = converter.decode_greedy(preds_index.data, preds_size.data)\n",
        "            elif opt.decode == 'beamsearch':\n",
        "                preds_str = converter.decode_beamsearch(preds, beamWidth=2)\n",
        "\n",
        "        else:\n",
        "            preds = model(image, text_for_pred, is_train=False)\n",
        "            forward_time = time.time() - start_time\n",
        "\n",
        "            preds = preds[:, :text_for_loss.shape[1] - 1, :]\n",
        "            target = text_for_loss[:, 1:]  # without [GO] Symbol\n",
        "            cost = criterion(preds.contiguous().view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
        "\n",
        "            # select max probabilty (greedy decoding) then decode index to character\n",
        "            _, preds_index = preds.max(2)\n",
        "            preds_str = converter.decode(preds_index, length_for_pred)\n",
        "            labels = converter.decode(text_for_loss[:, 1:], length_for_loss)\n",
        "\n",
        "        infer_time += forward_time\n",
        "        valid_loss_avg.add(cost)\n",
        "\n",
        "        # calculate accuracy & confidence score\n",
        "        preds_prob = F.softmax(preds, dim=2)\n",
        "        preds_max_prob, _ = preds_prob.max(dim=2)\n",
        "        confidence_score_list = []\n",
        "        \n",
        "        for gt, pred, pred_max_prob in zip(labels, preds_str, preds_max_prob):\n",
        "            if 'Attn' in opt.Prediction:\n",
        "                gt = gt[:gt.find('[s]')]\n",
        "                pred_EOS = pred.find('[s]')\n",
        "                pred = pred[:pred_EOS]  # prune after \"end of sentence\" token ([s])\n",
        "                pred_max_prob = pred_max_prob[:pred_EOS]\n",
        "\n",
        "            if pred == gt:\n",
        "                n_correct += 1\n",
        "\n",
        "            '''\n",
        "            (old version) ICDAR2017 DOST Normalized Edit Distance https://rrc.cvc.uab.es/?ch=7&com=tasks\n",
        "            \"For each word we calculate the normalized edit distance to the length of the ground truth transcription.\" \n",
        "            if len(gt) == 0:\n",
        "                norm_ED += 1\n",
        "            else:\n",
        "                norm_ED += edit_distance(pred, gt) / len(gt)\n",
        "            '''\n",
        "            \n",
        "            # ICDAR2019 Normalized Edit Distance \n",
        "            if len(gt) == 0 or len(pred) ==0:\n",
        "                norm_ED += 0\n",
        "            elif len(gt) > len(pred):\n",
        "                norm_ED += 1 - edit_distance(pred, gt) / len(gt)\n",
        "            else:\n",
        "                norm_ED += 1 - edit_distance(pred, gt) / len(pred)\n",
        "\n",
        "            # calculate confidence score (= multiply of pred_max_prob)\n",
        "            try:\n",
        "                confidence_score = pred_max_prob.cumprod(dim=0)[-1]\n",
        "            except:\n",
        "                confidence_score = 0  # for empty pred case, when prune after \"end of sentence\" token ([s])\n",
        "            confidence_score_list.append(confidence_score)\n",
        "            # print(pred, gt, pred==gt, confidence_score)\n",
        "\n",
        "    accuracy = n_correct / float(length_of_data) * 100\n",
        "    norm_ED = norm_ED / float(length_of_data) # ICDAR2019 Normalized Edit Distance\n",
        "\n",
        "    return valid_loss_avg.val(), accuracy, norm_ED, preds_str, confidence_score_list, labels, infer_time, length_of_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-lKb33_jl8W"
      },
      "outputs": [],
      "source": [
        "def get_config(file_path):\n",
        "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
        "        opt = yaml.safe_load(stream)\n",
        "    opt = AttrDict(opt)\n",
        "    if opt.lang_char == 'None':\n",
        "        characters = ''\n",
        "        for data in opt['select_data'].split('-'):\n",
        "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
        "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
        "            all_char = ''.join(df['words'])\n",
        "            characters += ''.join(set(all_char))\n",
        "        characters = sorted(set(characters))\n",
        "        opt.character= ''.join(characters)\n",
        "    else:\n",
        "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
        "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
        "    return opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-DAZD-tgUsg",
        "outputId": "4e2120e1-1e90-4a7b-d98d-33d20271a6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: all_data\n",
            "opt.select_data: ['en_train_filtered']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    all_data\t dataset: en_train_filtered\n",
            "all_data/en_train_filtered\n",
            "sub-directory:\t/en_train_filtered\t num samples: 68\n",
            "num total samples of en_train_filtered: 68 x 1.0 (total_data_usage_ratio) = 68\n",
            "num samples of en_train_filtered per batch: 32 x 1.0 (batch_ratio) = 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 32 = 32\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    all_data/en_val\t dataset: /\n",
            "all_data/en_val/\n",
            "sub-directory:\t/.\t num samples: 14\n",
            "--------------------------------------------------------------------------------\n",
            "No Transformation module specified\n",
            "model input parameters 64 600 20 1 256 256 208 34 None VGG BiLSTM CTC\n",
            "loading pretrained model from cyrillic_g2.pth\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (FeatureExtraction): VGG_FeatureExtractor(\n",
            "      (ConvNet): Sequential(\n",
            "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): ReLU(inplace=True)\n",
            "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): ReLU(inplace=True)\n",
            "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (9): ReLU(inplace=True)\n",
            "        (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "        (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (13): ReLU(inplace=True)\n",
            "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (16): ReLU(inplace=True)\n",
            "        (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "        (18): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (19): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Linear(in_features=256, out_features=208, bias=True)\n",
            "  )\n",
            ")\n",
            "Modules, Parameters\n",
            "module.FeatureExtraction.ConvNet.0.weight 288\n",
            "module.FeatureExtraction.ConvNet.0.bias 32\n",
            "module.FeatureExtraction.ConvNet.3.weight 18432\n",
            "module.FeatureExtraction.ConvNet.3.bias 64\n",
            "module.FeatureExtraction.ConvNet.6.weight 73728\n",
            "module.FeatureExtraction.ConvNet.6.bias 128\n",
            "module.FeatureExtraction.ConvNet.8.weight 147456\n",
            "module.FeatureExtraction.ConvNet.8.bias 128\n",
            "module.FeatureExtraction.ConvNet.11.weight 294912\n",
            "module.FeatureExtraction.ConvNet.12.weight 256\n",
            "module.FeatureExtraction.ConvNet.12.bias 256\n",
            "module.FeatureExtraction.ConvNet.14.weight 589824\n",
            "module.FeatureExtraction.ConvNet.15.weight 256\n",
            "module.FeatureExtraction.ConvNet.15.bias 256\n",
            "module.FeatureExtraction.ConvNet.18.weight 262144\n",
            "module.FeatureExtraction.ConvNet.18.bias 256\n",
            "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
            "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
            "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
            "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
            "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
            "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
            "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
            "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
            "module.SequenceModeling.0.linear.weight 131072\n",
            "module.SequenceModeling.0.linear.bias 256\n",
            "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
            "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
            "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
            "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
            "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
            "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
            "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
            "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
            "module.SequenceModeling.1.linear.weight 131072\n",
            "module.SequenceModeling.1.linear.bias 256\n",
            "module.Prediction.weight 53248\n",
            "module.Prediction.bias 208\n",
            "Total Trainable Params: 3809872\n",
            "Trainable params num :  3809872\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 1.0\n",
            "    maximize: False\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "number: 0123456789\n",
            "symbol: !\"#$%&'()*+,-./:;<=>?@[\\]№_`{|}~ €₽\n",
            "lang_char: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюяЂђЃѓЄєІіЇїЈјЉљЊњЋћЌќЎўЏџҐґҒғҚқҮүҲҳҶҷӀӏӢӣӨөӮӯ\n",
            "experiment_name: en_filtered\n",
            "train_data: all_data\n",
            "valid_data: all_data/en_val\n",
            "manualSeed: 1111\n",
            "workers: 6\n",
            "batch_size: 32\n",
            "num_iter: 5000\n",
            "valInterval: 500\n",
            "saved_model: cyrillic_g2.pth\n",
            "FT: False\n",
            "optim: False\n",
            "lr: 1.0\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "select_data: ['en_train_filtered']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 34\n",
            "imgH: 64\n",
            "imgW: 600\n",
            "rgb: False\n",
            "contrast_adjust: 0.0\n",
            "sensitive: True\n",
            "PAD: True\n",
            "data_filtering_off: False\n",
            "Transformation: None\n",
            "FeatureExtraction: VGG\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: CTC\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 256\n",
            "hidden_size: 256\n",
            "decode: greedy\n",
            "new_prediction: False\n",
            "freeze_FeatureFxtraction: False\n",
            "freeze_SequenceModeling: False\n",
            "character: 0123456789!\"#$%&'()*+,-./:;<=>?@[\\]№_`{|}~ €₽ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзийклмнопрстуфхцчшщъыьэюяЂђЃѓЄєІіЇїЈјЉљЊњЋћЌќЎўЏџҐґҒғҚқҮүҲҳҶҷӀӏӢӣӨөӮӯ\n",
            "num_class: 208\n",
            "---------------------------------------\n",
            "\n",
            "training time:  127.13664841651917\n",
            "[500/5000] Train loss: 0.03617, Valid loss: 0.30726, Elapsed_time: 127.13704\n",
            "Current_accuracy : 78.571, Current_norm_ED  : 0.9750\n",
            "Best_accuracy    : 78.571, Best_norm_ED     : 0.9750\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "КМ12977                   | КМ12977                   | 0.7065\tTrue\n",
            "С044ЕН51                  | С044ЕН51                  | 0.8931\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.8254752159118652\n",
            "training time:  123.25406861305237\n",
            "[1000/5000] Train loss: 0.00001, Valid loss: 0.34436, Elapsed_time: 251.21698\n",
            "Current_accuracy : 78.571, Current_norm_ED  : 0.9750\n",
            "Best_accuracy    : 78.571, Best_norm_ED     : 0.9750\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "А004АА777                 | А004АА777                 | 0.5919\tTrue\n",
            "С044ЕН51                  | С044ЕН51                  | 0.8663\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.5086948871612549\n",
            "training time:  126.19740557670593\n",
            "[1500/5000] Train loss: 0.00001, Valid loss: 0.34195, Elapsed_time: 377.92344\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "В999ОР99                  | В999ОР99                  | 0.8130\tTrue\n",
            "А271АА99                  | А271АА99                  | 0.9981\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.6201679706573486\n",
            "training time:  130.633216381073\n",
            "[2000/5000] Train loss: 0.00000, Valid loss: 0.33189, Elapsed_time: 509.17721\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "А271АА99                  | А271АА99                  | 0.9992\tTrue\n",
            "М222ММ02                  | М222ММ02                  | 0.5391\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.5427236557006836\n",
            "training time:  136.55754446983337\n",
            "[2500/5000] Train loss: 0.00000, Valid loss: 0.33124, Elapsed_time: 646.27878\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "А555МУ92                  | А555МУ92                  | 0.9997\tTrue\n",
            "Н502ЕР154                 | Н502ЕР154                 | 0.5898\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.5776188373565674\n",
            "training time:  141.13908791542053\n",
            "[3000/5000] Train loss: 0.00000, Valid loss: 0.33125, Elapsed_time: 787.99787\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "В999ОР99                  | В999ОР99                  | 0.8506\tTrue\n",
            "КМ12977                   | КМ12977                   | 0.7499\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.7371926307678223\n",
            "training time:  150.2889678478241\n",
            "[3500/5000] Train loss: 0.00000, Valid loss: 0.33230, Elapsed_time: 939.02651\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "Х27ХХ77                   | Х237ХХ77                  | 0.5159\tFalse\n",
            "Х007МН777                 | Х007МН777                 | 0.9695\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.636620283126831\n",
            "training time:  152.16671228408813\n",
            "[4000/5000] Train loss: 0.00000, Valid loss: 0.32554, Elapsed_time: 1091.83017\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "КМ12977                   | КМ12977                   | 0.8290\tTrue\n",
            "А004АА777                 | А004АА777                 | 0.8554\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.6653378009796143\n",
            "training time:  157.7139492034912\n",
            "[4500/5000] Train loss: 0.00000, Valid loss: 0.33951, Elapsed_time: 1250.21191\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "В999ОР99                  | В999ОР99                  | 0.7157\tTrue\n",
            "М640РВ72                  | М640РВ72                  | 0.5106\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.6864757537841797\n",
            "training time:  162.38239693641663\n",
            "[5000/5000] Train loss: 0.00000, Valid loss: 0.34262, Elapsed_time: 1413.28198\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "В001ВР777                 | В001ВР7777                | 0.9507\tFalse\n",
            "КМ12977                   | КМ12977                   | 0.7506\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.718132734298706\n",
            "end the training\n"
          ]
        }
      ],
      "source": [
        "opt = get_config(\"config_files/en_filtered_config.yaml\")\n",
        "train(opt, amp=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "pB8rybflr-S7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uo_qiPormrw",
        "outputId": "05a9d27d-e16b-4bc7-e3c4-02e2034d8545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/custom_easyocr.zip\n",
            "   creating: custom_easyocr/\n",
            "   creating: custom_easyocr/model/\n",
            "  inflating: custom_easyocr/model/custom_example.pth  \n",
            "   creating: custom_easyocr/user_network/\n",
            "  inflating: custom_easyocr/user_network/custom_example.py  \n",
            "  inflating: custom_easyocr/user_network/custom_example.yaml  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/custom_easyocr.zip\n",
        "!rm /content/custom_easyocr.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqDXAPFhOu2U"
      },
      "outputs": [],
      "source": [
        "!pip install jiwer\n",
        "!pip install easyocr\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3TIbyX_hIln8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import easyocr\n",
        "from jiwer import wer, cer\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGH4agWYNZSd",
        "outputId": "dc944fa7-05e4-43c4-815a-69739e16e5be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "1w9mOjgt6PUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b68c7a9-71c9-4bfd-b10b-edd3a7ceffcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v6.2-228-g6ae3dff Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "reader = easyocr.Reader(\n",
        "    ['ru'],\n",
        "    model_storage_directory='custom_easyocr/model',\n",
        "    user_network_directory='custom_easyocr/user_network',\n",
        "    recog_network='custom_example'\n",
        ")\n",
        "\n",
        "default_reader = easyocr.Reader(['ru'])\n",
        "\n",
        "model = torch.hub.load(\n",
        "    'yolov5', \n",
        "    'custom',                  \n",
        "    path='/content/drive/MyDrive/best.pt', \n",
        "    force_reload=True,\n",
        "    source='local'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dir_path, model, reader):\n",
        "    plates, plate_numbers = [], []\n",
        "    for root, dirs, files in os.walk(dir_path):  \n",
        "        for filename in files:\n",
        "            plates.append(filename)\n",
        "\n",
        "    for filename in plates:\n",
        "        image = cv2.imread(f'{dir_path}/{filename}')    \n",
        "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        result = model(img_gray)\n",
        "        cordinates = result.xyxyn[0][:, :-1]\n",
        "        width, height = image.shape[1], image.shape[0]\n",
        "\n",
        "        for row in cordinates:\n",
        "            x1, y1, x2, y2 = int(row[0]*width), int(row[1]*height), int(row[2]*width), int(row[3]*height)    \n",
        "            read = reader.readtext(\n",
        "                img_gray[y1:y2, x1:x2], \n",
        "                allowlist='0123456789АВЕКМНОРСТУХ'\n",
        "            )\n",
        "\n",
        "            plate = ''\n",
        "            for i in range(len(read)):\n",
        "                if i < 2 and read[i][-1] > 0.5:\n",
        "                    plate += read[i][-2]\n",
        "                elif read[i][-1] > 0.8:\n",
        "                    plate += read[i][-2]\n",
        "\n",
        "            plate_numbers.append(plate)\n",
        "    return plate_numbers"
      ],
      "metadata": {
        "id": "elUbGNAIKkDJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = [\n",
        "    'А471АА199', 'Х333АХ777', 'С313СС77', \n",
        "    'С222УУ47', 'Х001АМ95', 'Х001АМ97',\n",
        "    'Р3330А777', 'А001РТ125', 'О000ОО99', \n",
        "    'С684ВН199', 'Т008АО777', 'У222УУ47', \n",
        "    'Х001АМ777', 'Е888РН05',  'Е009КХ97', \n",
        "    'Е008ЕЕ77', 'Т222УУ777', 'А888OO77',\n",
        "    'Р777ВМ102', 'У333МА777', 'Т300МР77'\n",
        "]"
      ],
      "metadata": {
        "id": "TyJe9TvYNQ6f"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default = test('/content/test', model, default_reader)\n",
        "custom = test('/content/test', model, reader)"
      ],
      "metadata": {
        "id": "oIyzcGi3Mdi9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(custom)):\n",
        "    if custom[i] == '':\n",
        "        custom[i] = 'none'\n",
        "cer_custom = cer(custom, target)\n",
        "wer_custom = wer(custom, target)"
      ],
      "metadata": {
        "id": "F7qSZUoQPnww"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(default)):\n",
        "    if default[i] == '':\n",
        "        default[i] = 'none'\n",
        "cer_default = cer(default, target)\n",
        "wer_default = wer(default, target)"
      ],
      "metadata": {
        "id": "ezPXul_rVarN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(graund_trought, predict):\n",
        "    sum = 0\n",
        "    for i in range(len(graund_trought)):\n",
        "        sum += int(graund_trought[i] == predict[i])\n",
        "    return sum / len(graund_trought)"
      ],
      "metadata": {
        "id": "ZkMTy9UqSXGP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('custom easyocr:')\n",
        "print(f'CER: {cer_custom}')\n",
        "print(f'WER: {wer_custom}')\n",
        "print(f'accuracy: {accuracy(custom, target)}')\n",
        "print('\\neasyocr:')\n",
        "print(f'CER: {cer_default}')\n",
        "print(f'WER: {wer_default}')\n",
        "print(f'accuracy: {accuracy(default, target)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hxj9w_XsuKU",
        "outputId": "9dae3f5c-71e1-4f8d-8861-ef6702b45bcb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom easyocr:\n",
            "CER: 0.28846153846153844\n",
            "WER: 0.42857142857142855\n",
            "accuracy: 0.5714285714285714\n",
            "\n",
            "easyocr:\n",
            "CER: 0.5732484076433121\n",
            "WER: 0.9047619047619048\n",
            "accuracy: 0.09523809523809523\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}