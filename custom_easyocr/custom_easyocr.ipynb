{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "TsuA0MtYs9nc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLbLs7EFejXc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/JaidedAI/EasyOCR.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkGYnVHKjC9Q",
        "outputId": "250a9b5d-9089-42b2-f8ce-ebae62fbd426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/EasyOCR/trainer/all_data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/EasyOCR/trainer/all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpH3_Sfo1RUc"
      },
      "outputs": [],
      "source": [
        "!unzip /content/EasyOCR/trainer/all_data/en_val.zip\n",
        "!unzip /content/EasyOCR/trainer/all_data/en_train_filtered.zip\n",
        "\n",
        "!rm /content/EasyOCR/trainer/all_data/folder.txt\n",
        "!rm /content/EasyOCR/trainer/all_data/en_val.zip\n",
        "!rm /content/EasyOCR/trainer/all_data/en_train_filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0aascdNjFwg",
        "outputId": "fa10aae6-5219-4119-ea0b-9311685d9585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/EasyOCR/trainer\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sooI7ZIEJYu_",
        "outputId": "7f471e70-3373-4699-8903-f428d0753e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PIywV9_WZqNNfUIk6-bs598fX7OZTcbY\n",
            "To: /content/EasyOCR/trainer/cyrillic_g2.pth\n",
            "100% 15.3M/15.3M [00:00<00:00, 27.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown \"1PIywV9_WZqNNfUIk6-bs598fX7OZTcbY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORToxtllgGm_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "import yaml\n",
        "from utils import AttrDict\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb65PNq5gJZJ"
      },
      "outputs": [],
      "source": [
        "cudnn.benchmark = True\n",
        "cudnn.deterministic = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mjGZ8gMTPc1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "from model import Model\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from utils import CTCLabelConverter, AttnLabelConverter, Averager\n",
        "from dataset import hierarchical_dataset, AlignCollate, Batch_Balanced_Dataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def count_parameters(model):\n",
        "    print(\"Modules, Parameters\")\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        #table.add_row([name, param])\n",
        "        total_params+=param\n",
        "        print(name, param)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "def train(opt, show_number = 2, amp=False):\n",
        "    \"\"\" dataset preparation \"\"\"\n",
        "    if not opt.data_filtering_off:\n",
        "        print('Filtering the images containing characters which are not in opt.character')\n",
        "        print('Filtering the images whose label is longer than opt.batch_max_length')\n",
        "\n",
        "    opt.select_data = opt.select_data.split('-')\n",
        "    opt.batch_ratio = opt.batch_ratio.split('-')\n",
        "    train_dataset = Batch_Balanced_Dataset(opt)\n",
        "\n",
        "    log = open(f'./saved_models/{opt.experiment_name}/log_dataset.txt', 'a', encoding=\"utf8\")\n",
        "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD, contrast_adjust=opt.contrast_adjust)\n",
        "    valid_dataset, valid_dataset_log = hierarchical_dataset(root=opt.valid_data, opt=opt)\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=min(32, opt.batch_size),\n",
        "        shuffle=True,  # 'True' to check training progress with validation function.\n",
        "        num_workers=int(opt.workers), prefetch_factor=512,\n",
        "        collate_fn=AlignCollate_valid, pin_memory=True)\n",
        "    log.write(valid_dataset_log)\n",
        "    print('-' * 80)\n",
        "    log.write('-' * 80 + '\\n')\n",
        "    log.close()\n",
        "    \n",
        "    \"\"\" model configuration \"\"\"\n",
        "    if 'CTC' in opt.Prediction:\n",
        "        converter = CTCLabelConverter(opt.character)\n",
        "    else:\n",
        "        converter = AttnLabelConverter(opt.character)\n",
        "    opt.num_class = len(converter.character)\n",
        "\n",
        "    if opt.rgb:\n",
        "        opt.input_channel = 3\n",
        "    model = Model(opt)\n",
        "    print('model input parameters', opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel,\n",
        "          opt.hidden_size, opt.num_class, opt.batch_max_length, opt.Transformation, opt.FeatureExtraction,\n",
        "          opt.SequenceModeling, opt.Prediction)\n",
        "\n",
        "    if opt.saved_model != '':\n",
        "        pretrained_dict = torch.load(opt.saved_model)\n",
        "        if opt.new_prediction:\n",
        "            model.Prediction = nn.Linear(model.SequenceModeling_output, len(pretrained_dict['module.Prediction.weight']))  \n",
        "        \n",
        "        model = torch.nn.DataParallel(model).to(device) \n",
        "        print(f'loading pretrained model from {opt.saved_model}')\n",
        "        if opt.FT:\n",
        "            model.load_state_dict(pretrained_dict, strict=False)\n",
        "        else:\n",
        "            model.load_state_dict(pretrained_dict)\n",
        "        if opt.new_prediction:\n",
        "            model.module.Prediction = nn.Linear(model.module.SequenceModeling_output, opt.num_class)  \n",
        "            for name, param in model.module.Prediction.named_parameters():\n",
        "                if 'bias' in name:\n",
        "                    init.constant_(param, 0.0)\n",
        "                elif 'weight' in name:\n",
        "                    init.kaiming_normal_(param)\n",
        "            model = model.to(device) \n",
        "    else:\n",
        "        # weight initialization\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'localization_fc2' in name:\n",
        "                print(f'Skip {name} as it is already initialized')\n",
        "                continue\n",
        "            try:\n",
        "                if 'bias' in name:\n",
        "                    init.constant_(param, 0.0)\n",
        "                elif 'weight' in name:\n",
        "                    init.kaiming_normal_(param)\n",
        "            except Exception as e:  # for batchnorm.\n",
        "                if 'weight' in name:\n",
        "                    param.data.fill_(1)\n",
        "                continue\n",
        "        model = torch.nn.DataParallel(model).to(device)\n",
        "    \n",
        "    model.train() \n",
        "    print(\"Model:\")\n",
        "    print(model)\n",
        "    count_parameters(model)\n",
        "    \n",
        "    \"\"\" setup loss \"\"\"\n",
        "    if 'CTC' in opt.Prediction:\n",
        "        criterion = torch.nn.CTCLoss(zero_infinity=True).to(device)\n",
        "    else:\n",
        "        criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)  # ignore [GO] token = ignore index 0\n",
        "    # loss averager\n",
        "    loss_avg = Averager()\n",
        "\n",
        "    # freeze some layers\n",
        "    try:\n",
        "        if opt.freeze_FeatureFxtraction:\n",
        "            for param in model.module.FeatureExtraction.parameters():\n",
        "                param.requires_grad = False\n",
        "        if opt.freeze_SequenceModeling:\n",
        "            for param in model.module.SequenceModeling.parameters():\n",
        "                param.requires_grad = False\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # filter that only require gradient decent\n",
        "    filtered_parameters = []\n",
        "    params_num = []\n",
        "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
        "        filtered_parameters.append(p)\n",
        "        params_num.append(np.prod(p.size()))\n",
        "    print('Trainable params num : ', sum(params_num))\n",
        "    # [print(name, p.numel()) for name, p in filter(lambda p: p[1].requires_grad, model.named_parameters())]\n",
        "\n",
        "    # setup optimizer\n",
        "    if opt.optim=='adam':\n",
        "        #optimizer = optim.Adam(filtered_parameters, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "        optimizer = optim.Adam(filtered_parameters)\n",
        "    else:\n",
        "        optimizer = optim.Adadelta(filtered_parameters, lr=opt.lr, rho=opt.rho, eps=opt.eps)\n",
        "    print(\"Optimizer:\")\n",
        "    print(optimizer)\n",
        "\n",
        "    \"\"\" final options \"\"\"\n",
        "    # print(opt)\n",
        "    with open(f'./saved_models/{opt.experiment_name}/opt.txt', 'a', encoding=\"utf8\") as opt_file:\n",
        "        opt_log = '------------ Options -------------\\n'\n",
        "        args = vars(opt)\n",
        "        for k, v in args.items():\n",
        "            opt_log += f'{str(k)}: {str(v)}\\n'\n",
        "        opt_log += '---------------------------------------\\n'\n",
        "        print(opt_log)\n",
        "        opt_file.write(opt_log)\n",
        "\n",
        "    \"\"\" start training \"\"\"\n",
        "    start_iter = 0\n",
        "    if opt.saved_model != '':\n",
        "        try:\n",
        "            start_iter = int(opt.saved_model.split('_')[-1].split('.')[0])\n",
        "            print(f'continue to train, start_iter: {start_iter}')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    start_time = time.time()\n",
        "    best_accuracy = -1\n",
        "    best_norm_ED = -1\n",
        "    i = start_iter\n",
        "\n",
        "    scaler = GradScaler()\n",
        "    t1= time.time()\n",
        "        \n",
        "    while(True):\n",
        "        # train part\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        \n",
        "        if amp:\n",
        "            with autocast():\n",
        "                image_tensors, labels = train_dataset.get_batch()\n",
        "                image = image_tensors.to(device)\n",
        "                text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
        "                batch_size = image.size(0)\n",
        "\n",
        "                if 'CTC' in opt.Prediction:\n",
        "                    preds = model(image, text).log_softmax(2)\n",
        "                    preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
        "                    preds = preds.permute(1, 0, 2)\n",
        "                    torch.backends.cudnn.enabled = False\n",
        "                    cost = criterion(preds, text.to(device), preds_size.to(device), length.to(device))\n",
        "                    torch.backends.cudnn.enabled = True\n",
        "                else:\n",
        "                    preds = model(image, text[:, :-1])  # align with Attention.forward\n",
        "                    target = text[:, 1:]  # without [GO] Symbol\n",
        "                    cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
        "            scaler.scale(cost).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            image_tensors, labels = train_dataset.get_batch()\n",
        "            image = image_tensors.to(device)\n",
        "            text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
        "            batch_size = image.size(0)\n",
        "            if 'CTC' in opt.Prediction:\n",
        "                preds = model(image, text).log_softmax(2)\n",
        "                preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
        "                preds = preds.permute(1, 0, 2)\n",
        "                torch.backends.cudnn.enabled = False\n",
        "                cost = criterion(preds, text.to(device), preds_size.to(device), length.to(device))\n",
        "                torch.backends.cudnn.enabled = True\n",
        "            else:\n",
        "                preds = model(image, text[:, :-1])  # align with Attention.forward\n",
        "                target = text[:, 1:]  # without [GO] Symbol\n",
        "                cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
        "            cost.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip) \n",
        "            optimizer.step()\n",
        "        loss_avg.add(cost)\n",
        "\n",
        "        # validation part\n",
        "        if (i % opt.valInterval == 0) and (i!=0):\n",
        "            print('training time: ', time.time()-t1)\n",
        "            t1=time.time()\n",
        "            elapsed_time = time.time() - start_time\n",
        "            # for log\n",
        "            with open(f'./saved_models/{opt.experiment_name}/log_train.txt', 'a', encoding=\"utf8\") as log:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels,\\\n",
        "                    infer_time, length_of_data = validation(model, criterion, valid_loader, converter, opt, device)\n",
        "                model.train()\n",
        "\n",
        "                # training loss and validation loss\n",
        "                loss_log = f'[{i}/{opt.num_iter}] Train loss: {loss_avg.val():0.5f}, Valid loss: {valid_loss:0.5f}, Elapsed_time: {elapsed_time:0.5f}'\n",
        "                loss_avg.reset()\n",
        "\n",
        "                current_model_log = f'{\"Current_accuracy\":17s}: {current_accuracy:0.3f}, {\"Current_norm_ED\":17s}: {current_norm_ED:0.4f}'\n",
        "\n",
        "                # keep best accuracy model (on valid dataset)\n",
        "                if current_accuracy > best_accuracy:\n",
        "                    best_accuracy = current_accuracy\n",
        "                    torch.save(model.state_dict(), f'./saved_models/{opt.experiment_name}/best_accuracy.pth')\n",
        "                if current_norm_ED > best_norm_ED:\n",
        "                    best_norm_ED = current_norm_ED\n",
        "                    torch.save(model.state_dict(), f'./saved_models/{opt.experiment_name}/best_norm_ED.pth')\n",
        "                best_model_log = f'{\"Best_accuracy\":17s}: {best_accuracy:0.3f}, {\"Best_norm_ED\":17s}: {best_norm_ED:0.4f}'\n",
        "\n",
        "                loss_model_log = f'{loss_log}\\n{current_model_log}\\n{best_model_log}'\n",
        "                print(loss_model_log)\n",
        "                log.write(loss_model_log + '\\n')\n",
        "\n",
        "                # show some predicted results\n",
        "                dashed_line = '-' * 80\n",
        "                head = f'{\"Ground Truth\":25s} | {\"Prediction\":25s} | Confidence Score & T/F'\n",
        "                predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
        "                \n",
        "                #show_number = min(show_number, len(labels))\n",
        "                \n",
        "                start = random.randint(0,len(labels) - show_number )    \n",
        "                for gt, pred, confidence in zip(labels[start:start+show_number], preds[start:start+show_number], confidence_score[start:start+show_number]):\n",
        "                    if 'Attn' in opt.Prediction:\n",
        "                        gt = gt[:gt.find('[s]')]\n",
        "                        pred = pred[:pred.find('[s]')]\n",
        "\n",
        "                    predicted_result_log += f'{gt:25s} | {pred:25s} | {confidence:0.4f}\\t{str(pred == gt)}\\n'\n",
        "                predicted_result_log += f'{dashed_line}'\n",
        "                print(predicted_result_log)\n",
        "                log.write(predicted_result_log + '\\n')\n",
        "                print('validation time: ', time.time()-t1)\n",
        "                t1=time.time()\n",
        "        # save model per 1e+4 iter.\n",
        "        if (i + 1) % 1e+4 == 0:\n",
        "            torch.save(\n",
        "                model.state_dict(), f'./saved_models/{opt.experiment_name}/iter_{i+1}.pth')\n",
        "\n",
        "        if i == opt.num_iter:\n",
        "            print('end the training')\n",
        "            torch.save(model.state_dict(), f'./saved_models/{opt.experiment_name}/iter_{i+1}.pth')\n",
        "            break\n",
        "        i += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kKVpyAQTgYy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import string\n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from nltk.metrics.distance import edit_distance\n",
        "\n",
        "from model import Model\n",
        "from utils import CTCLabelConverter, AttnLabelConverter, Averager\n",
        "from dataset import hierarchical_dataset, AlignCollate\n",
        "\n",
        "def validation(model, criterion, evaluation_loader, converter, opt, device):\n",
        "    \"\"\" validation or evaluation \"\"\"\n",
        "    n_correct = 0\n",
        "    norm_ED = 0\n",
        "    length_of_data = 0\n",
        "    infer_time = 0\n",
        "    valid_loss_avg = Averager()\n",
        "\n",
        "    for i, (image_tensors, labels) in enumerate(evaluation_loader):\n",
        "        batch_size = image_tensors.size(0)\n",
        "        length_of_data = length_of_data + batch_size\n",
        "        image = image_tensors.to(device)\n",
        "        # For max length prediction\n",
        "        length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)\n",
        "        text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)\n",
        "\n",
        "        text_for_loss, length_for_loss = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
        "        \n",
        "        start_time = time.time()\n",
        "        if 'CTC' in opt.Prediction:\n",
        "            preds = model(image, text_for_pred)\n",
        "            forward_time = time.time() - start_time\n",
        "\n",
        "            # Calculate evaluation loss for CTC decoder.\n",
        "            preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
        "            # permute 'preds' to use CTCloss format\n",
        "            cost = criterion(preds.log_softmax(2).permute(1, 0, 2), text_for_loss, preds_size, length_for_loss)\n",
        "\n",
        "            if opt.decode == 'greedy':\n",
        "                # Select max probabilty (greedy decoding) then decode index to character\n",
        "                _, preds_index = preds.max(2)\n",
        "                preds_index = preds_index.view(-1)\n",
        "                preds_str = converter.decode_greedy(preds_index.data, preds_size.data)\n",
        "            elif opt.decode == 'beamsearch':\n",
        "                preds_str = converter.decode_beamsearch(preds, beamWidth=2)\n",
        "\n",
        "        else:\n",
        "            preds = model(image, text_for_pred, is_train=False)\n",
        "            forward_time = time.time() - start_time\n",
        "\n",
        "            preds = preds[:, :text_for_loss.shape[1] - 1, :]\n",
        "            target = text_for_loss[:, 1:]  # without [GO] Symbol\n",
        "            cost = criterion(preds.contiguous().view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
        "\n",
        "            # select max probabilty (greedy decoding) then decode index to character\n",
        "            _, preds_index = preds.max(2)\n",
        "            preds_str = converter.decode(preds_index, length_for_pred)\n",
        "            labels = converter.decode(text_for_loss[:, 1:], length_for_loss)\n",
        "\n",
        "        infer_time += forward_time\n",
        "        valid_loss_avg.add(cost)\n",
        "\n",
        "        # calculate accuracy & confidence score\n",
        "        preds_prob = F.softmax(preds, dim=2)\n",
        "        preds_max_prob, _ = preds_prob.max(dim=2)\n",
        "        confidence_score_list = []\n",
        "        \n",
        "        for gt, pred, pred_max_prob in zip(labels, preds_str, preds_max_prob):\n",
        "            if 'Attn' in opt.Prediction:\n",
        "                gt = gt[:gt.find('[s]')]\n",
        "                pred_EOS = pred.find('[s]')\n",
        "                pred = pred[:pred_EOS]  # prune after \"end of sentence\" token ([s])\n",
        "                pred_max_prob = pred_max_prob[:pred_EOS]\n",
        "\n",
        "            if pred == gt:\n",
        "                n_correct += 1\n",
        "\n",
        "            '''\n",
        "            (old version) ICDAR2017 DOST Normalized Edit Distance https://rrc.cvc.uab.es/?ch=7&com=tasks\n",
        "            \"For each word we calculate the normalized edit distance to the length of the ground truth transcription.\" \n",
        "            if len(gt) == 0:\n",
        "                norm_ED += 1\n",
        "            else:\n",
        "                norm_ED += edit_distance(pred, gt) / len(gt)\n",
        "            '''\n",
        "            \n",
        "            # ICDAR2019 Normalized Edit Distance \n",
        "            if len(gt) == 0 or len(pred) ==0:\n",
        "                norm_ED += 0\n",
        "            elif len(gt) > len(pred):\n",
        "                norm_ED += 1 - edit_distance(pred, gt) / len(gt)\n",
        "            else:\n",
        "                norm_ED += 1 - edit_distance(pred, gt) / len(pred)\n",
        "\n",
        "            # calculate confidence score (= multiply of pred_max_prob)\n",
        "            try:\n",
        "                confidence_score = pred_max_prob.cumprod(dim=0)[-1]\n",
        "            except:\n",
        "                confidence_score = 0  # for empty pred case, when prune after \"end of sentence\" token ([s])\n",
        "            confidence_score_list.append(confidence_score)\n",
        "            # print(pred, gt, pred==gt, confidence_score)\n",
        "\n",
        "    accuracy = n_correct / float(length_of_data) * 100\n",
        "    norm_ED = norm_ED / float(length_of_data) # ICDAR2019 Normalized Edit Distance\n",
        "\n",
        "    return valid_loss_avg.val(), accuracy, norm_ED, preds_str, confidence_score_list, labels, infer_time, length_of_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-lKb33_jl8W"
      },
      "outputs": [],
      "source": [
        "def get_config(file_path):\n",
        "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
        "        opt = yaml.safe_load(stream)\n",
        "    opt = AttrDict(opt)\n",
        "    if opt.lang_char == 'None':\n",
        "        characters = ''\n",
        "        for data in opt['select_data'].split('-'):\n",
        "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
        "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
        "            all_char = ''.join(df['words'])\n",
        "            characters += ''.join(set(all_char))\n",
        "        characters = sorted(set(characters))\n",
        "        opt.character= ''.join(characters)\n",
        "    else:\n",
        "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
        "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
        "    return opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-DAZD-tgUsg",
        "outputId": "4e2120e1-1e90-4a7b-d98d-33d20271a6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: all_data\n",
            "opt.select_data: ['en_train_filtered']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    all_data\t dataset: en_train_filtered\n",
            "all_data/en_train_filtered\n",
            "sub-directory:\t/en_train_filtered\t num samples: 68\n",
            "num total samples of en_train_filtered: 68 x 1.0 (total_data_usage_ratio) = 68\n",
            "num samples of en_train_filtered per batch: 32 x 1.0 (batch_ratio) = 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 32 = 32\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    all_data/en_val\t dataset: /\n",
            "all_data/en_val/\n",
            "sub-directory:\t/.\t num samples: 14\n",
            "--------------------------------------------------------------------------------\n",
            "No Transformation module specified\n",
            "model input parameters 64 600 20 1 256 256 208 34 None VGG BiLSTM CTC\n",
            "loading pretrained model from cyrillic_g2.pth\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (FeatureExtraction): VGG_FeatureExtractor(\n",
            "      (ConvNet): Sequential(\n",
            "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): ReLU(inplace=True)\n",
            "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): ReLU(inplace=True)\n",
            "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (9): ReLU(inplace=True)\n",
            "        (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "        (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (13): ReLU(inplace=True)\n",
            "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (16): ReLU(inplace=True)\n",
            "        (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
            "        (18): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "        (19): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Linear(in_features=256, out_features=208, bias=True)\n",
            "  )\n",
            ")\n",
            "Modules, Parameters\n",
            "module.FeatureExtraction.ConvNet.0.weight 288\n",
            "module.FeatureExtraction.ConvNet.0.bias 32\n",
            "module.FeatureExtraction.ConvNet.3.weight 18432\n",
            "module.FeatureExtraction.ConvNet.3.bias 64\n",
            "module.FeatureExtraction.ConvNet.6.weight 73728\n",
            "module.FeatureExtraction.ConvNet.6.bias 128\n",
            "module.FeatureExtraction.ConvNet.8.weight 147456\n",
            "module.FeatureExtraction.ConvNet.8.bias 128\n",
            "module.FeatureExtraction.ConvNet.11.weight 294912\n",
            "module.FeatureExtraction.ConvNet.12.weight 256\n",
            "module.FeatureExtraction.ConvNet.12.bias 256\n",
            "module.FeatureExtraction.ConvNet.14.weight 589824\n",
            "module.FeatureExtraction.ConvNet.15.weight 256\n",
            "module.FeatureExtraction.ConvNet.15.bias 256\n",
            "module.FeatureExtraction.ConvNet.18.weight 262144\n",
            "module.FeatureExtraction.ConvNet.18.bias 256\n",
            "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
            "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
            "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
            "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
            "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
            "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
            "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
            "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
            "module.SequenceModeling.0.linear.weight 131072\n",
            "module.SequenceModeling.0.linear.bias 256\n",
            "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
            "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
            "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
            "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
            "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
            "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
            "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
            "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
            "module.SequenceModeling.1.linear.weight 131072\n",
            "module.SequenceModeling.1.linear.bias 256\n",
            "module.Prediction.weight 53248\n",
            "module.Prediction.bias 208\n",
            "Total Trainable Params: 3809872\n",
            "Trainable params num :  3809872\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 1.0\n",
            "    maximize: False\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "number: 0123456789\n",
            "symbol: !\"#$%&'()*+,-./:;<=>?@[\\]‚Ññ_`{|}~ ‚Ç¨‚ÇΩ\n",
            "lang_char: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è–Ç—í–É—ì–Ñ—î–Ü—ñ–á—ó–à—ò–â—ô–ä—ö–ã—õ–å—ú–é—û–è—ü“ê“ë“í“ì“ö“õ“Æ“Ø“≤“≥“∂“∑”Ä”è”¢”£”®”©”Æ”Ø\n",
            "experiment_name: en_filtered\n",
            "train_data: all_data\n",
            "valid_data: all_data/en_val\n",
            "manualSeed: 1111\n",
            "workers: 6\n",
            "batch_size: 32\n",
            "num_iter: 5000\n",
            "valInterval: 500\n",
            "saved_model: cyrillic_g2.pth\n",
            "FT: False\n",
            "optim: False\n",
            "lr: 1.0\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "select_data: ['en_train_filtered']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 34\n",
            "imgH: 64\n",
            "imgW: 600\n",
            "rgb: False\n",
            "contrast_adjust: 0.0\n",
            "sensitive: True\n",
            "PAD: True\n",
            "data_filtering_off: False\n",
            "Transformation: None\n",
            "FeatureExtraction: VGG\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: CTC\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 256\n",
            "hidden_size: 256\n",
            "decode: greedy\n",
            "new_prediction: False\n",
            "freeze_FeatureFxtraction: False\n",
            "freeze_SequenceModeling: False\n",
            "character: 0123456789!\"#$%&'()*+,-./:;<=>?@[\\]‚Ññ_`{|}~ ‚Ç¨‚ÇΩABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è–Ç—í–É—ì–Ñ—î–Ü—ñ–á—ó–à—ò–â—ô–ä—ö–ã—õ–å—ú–é—û–è—ü“ê“ë“í“ì“ö“õ“Æ“Ø“≤“≥“∂“∑”Ä”è”¢”£”®”©”Æ”Ø\n",
            "num_class: 208\n",
            "---------------------------------------\n",
            "\n",
            "training time:  127.13664841651917\n",
            "[500/5000] Train loss: 0.03617, Valid loss: 0.30726, Elapsed_time: 127.13704\n",
            "Current_accuracy : 78.571, Current_norm_ED  : 0.9750\n",
            "Best_accuracy    : 78.571, Best_norm_ED     : 0.9750\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–ö–ú12977                   | –ö–ú12977                   | 0.7065\tTrue\n",
            "–°044–ï–ù51                  | –°044–ï–ù51                  | 0.8931\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.8254752159118652\n",
            "training time:  123.25406861305237\n",
            "[1000/5000] Train loss: 0.00001, Valid loss: 0.34436, Elapsed_time: 251.21698\n",
            "Current_accuracy : 78.571, Current_norm_ED  : 0.9750\n",
            "Best_accuracy    : 78.571, Best_norm_ED     : 0.9750\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–ê004–ê–ê777                 | –ê004–ê–ê777                 | 0.5919\tTrue\n",
            "–°044–ï–ù51                  | –°044–ï–ù51                  | 0.8663\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.5086948871612549\n",
            "training time:  126.19740557670593\n",
            "[1500/5000] Train loss: 0.00001, Valid loss: 0.34195, Elapsed_time: 377.92344\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–í999–û–†99                  | –í999–û–†99                  | 0.8130\tTrue\n",
            "–ê271–ê–ê99                  | –ê271–ê–ê99                  | 0.9981\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.6201679706573486\n",
            "training time:  130.633216381073\n",
            "[2000/5000] Train loss: 0.00000, Valid loss: 0.33189, Elapsed_time: 509.17721\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–ê271–ê–ê99                  | –ê271–ê–ê99                  | 0.9992\tTrue\n",
            "–ú222–ú–ú02                  | –ú222–ú–ú02                  | 0.5391\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.5427236557006836\n",
            "training time:  136.55754446983337\n",
            "[2500/5000] Train loss: 0.00000, Valid loss: 0.33124, Elapsed_time: 646.27878\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–ê555–ú–£92                  | –ê555–ú–£92                  | 0.9997\tTrue\n",
            "–ù502–ï–†154                 | –ù502–ï–†154                 | 0.5898\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.5776188373565674\n",
            "training time:  141.13908791542053\n",
            "[3000/5000] Train loss: 0.00000, Valid loss: 0.33125, Elapsed_time: 787.99787\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–í999–û–†99                  | –í999–û–†99                  | 0.8506\tTrue\n",
            "–ö–ú12977                   | –ö–ú12977                   | 0.7499\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.7371926307678223\n",
            "training time:  150.2889678478241\n",
            "[3500/5000] Train loss: 0.00000, Valid loss: 0.33230, Elapsed_time: 939.02651\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–•27–•–•77                   | –•237–•–•77                  | 0.5159\tFalse\n",
            "–•007–ú–ù777                 | –•007–ú–ù777                 | 0.9695\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.636620283126831\n",
            "training time:  152.16671228408813\n",
            "[4000/5000] Train loss: 0.00000, Valid loss: 0.32554, Elapsed_time: 1091.83017\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–ö–ú12977                   | –ö–ú12977                   | 0.8290\tTrue\n",
            "–ê004–ê–ê777                 | –ê004–ê–ê777                 | 0.8554\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.6653378009796143\n",
            "training time:  157.7139492034912\n",
            "[4500/5000] Train loss: 0.00000, Valid loss: 0.33951, Elapsed_time: 1250.21191\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–í999–û–†99                  | –í999–û–†99                  | 0.7157\tTrue\n",
            "–ú640–†–í72                  | –ú640–†–í72                  | 0.5106\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.6864757537841797\n",
            "training time:  162.38239693641663\n",
            "[5000/5000] Train loss: 0.00000, Valid loss: 0.34262, Elapsed_time: 1413.28198\n",
            "Current_accuracy : 85.714, Current_norm_ED  : 0.9839\n",
            "Best_accuracy    : 85.714, Best_norm_ED     : 0.9839\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "–í001–í–†777                 | –í001–í–†7777                | 0.9507\tFalse\n",
            "–ö–ú12977                   | –ö–ú12977                   | 0.7506\tTrue\n",
            "--------------------------------------------------------------------------------\n",
            "validation time:  0.718132734298706\n",
            "end the training\n"
          ]
        }
      ],
      "source": [
        "opt = get_config(\"config_files/en_filtered_config.yaml\")\n",
        "train(opt, amp=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "pB8rybflr-S7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uo_qiPormrw",
        "outputId": "05a9d27d-e16b-4bc7-e3c4-02e2034d8545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/custom_easyocr.zip\n",
            "   creating: custom_easyocr/\n",
            "   creating: custom_easyocr/model/\n",
            "  inflating: custom_easyocr/model/custom_example.pth  \n",
            "   creating: custom_easyocr/user_network/\n",
            "  inflating: custom_easyocr/user_network/custom_example.py  \n",
            "  inflating: custom_easyocr/user_network/custom_example.yaml  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/custom_easyocr.zip\n",
        "!rm /content/custom_easyocr.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqDXAPFhOu2U"
      },
      "outputs": [],
      "source": [
        "!pip install jiwer\n",
        "!pip install easyocr\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3TIbyX_hIln8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import easyocr\n",
        "from jiwer import wer, cer\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGH4agWYNZSd",
        "outputId": "dc944fa7-05e4-43c4-815a-69739e16e5be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "1w9mOjgt6PUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b68c7a9-71c9-4bfd-b10b-edd3a7ceffcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v6.2-228-g6ae3dff Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "reader = easyocr.Reader(\n",
        "    ['ru'],\n",
        "    model_storage_directory='custom_easyocr/model',\n",
        "    user_network_directory='custom_easyocr/user_network',\n",
        "    recog_network='custom_example'\n",
        ")\n",
        "\n",
        "default_reader = easyocr.Reader(['ru'])\n",
        "\n",
        "model = torch.hub.load(\n",
        "    'yolov5', \n",
        "    'custom',                  \n",
        "    path='/content/drive/MyDrive/best.pt', \n",
        "    force_reload=True,\n",
        "    source='local'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dir_path, model, reader):\n",
        "    plates, plate_numbers = [], []\n",
        "    for root, dirs, files in os.walk(dir_path):  \n",
        "        for filename in files:\n",
        "            plates.append(filename)\n",
        "\n",
        "    for filename in plates:\n",
        "        image = cv2.imread(f'{dir_path}/{filename}')    \n",
        "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        result = model(img_gray)\n",
        "        cordinates = result.xyxyn[0][:, :-1]\n",
        "        width, height = image.shape[1], image.shape[0]\n",
        "\n",
        "        for row in cordinates:\n",
        "            x1, y1, x2, y2 = int(row[0]*width), int(row[1]*height), int(row[2]*width), int(row[3]*height)    \n",
        "            read = reader.readtext(\n",
        "                img_gray[y1:y2, x1:x2], \n",
        "                allowlist='0123456789–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•'\n",
        "            )\n",
        "\n",
        "            plate = ''\n",
        "            for i in range(len(read)):\n",
        "                if i < 2 and read[i][-1] > 0.5:\n",
        "                    plate += read[i][-2]\n",
        "                elif read[i][-1] > 0.8:\n",
        "                    plate += read[i][-2]\n",
        "\n",
        "            plate_numbers.append(plate)\n",
        "    return plate_numbers"
      ],
      "metadata": {
        "id": "elUbGNAIKkDJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = [\n",
        "    '–ê471–ê–ê199', '–•333–ê–•777', '–°313–°–°77', \n",
        "    '–°222–£–£47', '–•001–ê–ú95', '–•001–ê–ú97',\n",
        "    '–†3330–ê777', '–ê001–†–¢125', '–û000–û–û99', \n",
        "    '–°684–í–ù199', '–¢008–ê–û777', '–£222–£–£47', \n",
        "    '–•001–ê–ú777', '–ï888–†–ù05',  '–ï009–ö–•97', \n",
        "    '–ï008–ï–ï77', '–¢222–£–£777', '–ê888OO77',\n",
        "    '–†777–í–ú102', '–£333–ú–ê777', '–¢300–ú–†77'\n",
        "]"
      ],
      "metadata": {
        "id": "TyJe9TvYNQ6f"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default = test('/content/test', model, default_reader)\n",
        "custom = test('/content/test', model, reader)"
      ],
      "metadata": {
        "id": "oIyzcGi3Mdi9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(custom)):\n",
        "    if custom[i] == '':\n",
        "        custom[i] = 'none'\n",
        "cer_custom = cer(custom, target)\n",
        "wer_custom = wer(custom, target)"
      ],
      "metadata": {
        "id": "F7qSZUoQPnww"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(default)):\n",
        "    if default[i] == '':\n",
        "        default[i] = 'none'\n",
        "cer_default = cer(default, target)\n",
        "wer_default = wer(default, target)"
      ],
      "metadata": {
        "id": "ezPXul_rVarN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(graund_trought, predict):\n",
        "    sum = 0\n",
        "    for i in range(len(graund_trought)):\n",
        "        sum += int(graund_trought[i] == predict[i])\n",
        "    return sum / len(graund_trought)"
      ],
      "metadata": {
        "id": "ZkMTy9UqSXGP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('custom easyocr:')\n",
        "print(f'CER: {cer_custom}')\n",
        "print(f'WER: {wer_custom}')\n",
        "print(f'accuracy: {accuracy(custom, target)}')\n",
        "print('\\neasyocr:')\n",
        "print(f'CER: {cer_default}')\n",
        "print(f'WER: {wer_default}')\n",
        "print(f'accuracy: {accuracy(default, target)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hxj9w_XsuKU",
        "outputId": "9dae3f5c-71e1-4f8d-8861-ef6702b45bcb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom easyocr:\n",
            "CER: 0.28846153846153844\n",
            "WER: 0.42857142857142855\n",
            "accuracy: 0.5714285714285714\n",
            "\n",
            "easyocr:\n",
            "CER: 0.5732484076433121\n",
            "WER: 0.9047619047619048\n",
            "accuracy: 0.09523809523809523\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}